{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d64c75f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Make sure this matches your worker observation builder\n",
    "from hrl.worker_env import TableTennisWorker\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from config import Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b6f38bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting relative offsets …\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30000/30000 [05:33<00:00, 90.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Suggested goal bounds ===\n",
      "goal_low  = [2.6226827461719515, 0.09191729348897937, -0.27048435640335083, 2.733618104457855, -0.573699263960123, 0.2]\n",
      "goal_high = [3.141523899316788, 1.236468253314495, -0.15279872941970826, 3.25203111410141, 0.5706091401278972, 0.8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "\n",
    "from config import Config\n",
    "from hrl.worker_env import TableTennisWorker\n",
    "\n",
    "def reset_env(venv):\n",
    "    result = venv.reset()\n",
    "    return result[0] if isinstance(result, tuple) else result\n",
    "\n",
    "def get_base_env(venv):\n",
    "    \"\"\"\n",
    "    Unwrap DummyVecEnv / Monitor / VecNormalize\n",
    "    down to the base gym env that has obs_dict.\n",
    "    \"\"\"\n",
    "    env = venv.envs[0]\n",
    "    while hasattr(env, \"env\"):\n",
    "        env = env.env\n",
    "    return env.unwrapped\n",
    "\n",
    "def collect_relative_offsets(cfg, num_steps=30000):\n",
    "    venv = DummyVecEnv([lambda: TableTennisWorker(cfg)])\n",
    "    base_env = get_base_env(venv)\n",
    "\n",
    "    dxs, dys, dzs = [], [], []\n",
    "    dpxs, dpys = [], []\n",
    "    dts = []\n",
    "\n",
    "    reset_env(venv)\n",
    "    for _ in tqdm(range(num_steps)):\n",
    "        action = [venv.action_space.sample()]\n",
    "        out = venv.step(action)\n",
    "\n",
    "        obs_dict = base_env.obs_dict  # raw MyoSuite obs\n",
    "        ball_pos = np.asarray(obs_dict[\"ball_pos\"], np.float32)\n",
    "        paddle_pos = np.asarray(obs_dict[\"paddle_pos\"], np.float32)\n",
    "        pelvis_xy = np.asarray(obs_dict[\"pelvis_pos\"][:2], np.float32)\n",
    "        t = float(obs_dict[\"time\"])\n",
    "\n",
    "        # Relative differences\n",
    "        dx, dy, dz = paddle_pos - ball_pos\n",
    "        dpx, dpy = pelvis_xy - ball_pos[:2]\n",
    "\n",
    "        dxs.append(dx)\n",
    "        dys.append(dy)\n",
    "        dzs.append(dz)\n",
    "        dpxs.append(dpx)\n",
    "        dpys.append(dpy)\n",
    "        dts.append(t)\n",
    "\n",
    "        done = bool(out[2][0] or out[3][0])\n",
    "        if done:\n",
    "            reset_env(venv)\n",
    "\n",
    "    venv.close()\n",
    "\n",
    "    return {\n",
    "        \"dx\": np.array(dxs),\n",
    "        \"dy\": np.array(dys),\n",
    "        \"dz\": np.array(dzs),\n",
    "        \"dpx\": np.array(dpxs),\n",
    "        \"dpy\": np.array(dpys),\n",
    "        \"dt\": np.array(dts),\n",
    "    }\n",
    "\n",
    "def suggest_goal_bounds(data, pct_min=1, pct_max=99, slack=1.2):\n",
    "    low, high = {}, {}\n",
    "    for key, values in data.items():\n",
    "        lo = np.percentile(values, pct_min)\n",
    "        hi = np.percentile(values, pct_max)\n",
    "        center = 0.5 * (lo + hi)\n",
    "        width = (hi - lo) * slack\n",
    "        low[key]  = center - 0.5 * width\n",
    "        high[key] = center + 0.5 * width\n",
    "    return low, high\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    cfg = Config()\n",
    "    print(\"Collecting relative offsets …\")\n",
    "    data = collect_relative_offsets(cfg, num_steps=30000)\n",
    "\n",
    "    low, high = suggest_goal_bounds(data, pct_min=1, pct_max=99, slack=1.2)\n",
    "    print(\"=== Suggested goal bounds ===\")\n",
    "    print(\"goal_low  =\", [\n",
    "        low[\"dx\"], low[\"dy\"], low[\"dz\"],\n",
    "        low[\"dpx\"], low[\"dpy\"], 0.2\n",
    "    ])\n",
    "    print(\"goal_high =\", [\n",
    "        high[\"dx\"], high[\"dy\"], high[\"dz\"],\n",
    "        high[\"dpx\"], high[\"dpy\"], 0.8\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b168eb02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n",
      "Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n",
      "Users of this version of Gym should be able to simply replace 'import gym' with 'import gymnasium as gym' in the vast majority of cases.\n",
      "See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n",
      "/home/ubuntu/myochallenge_2025eval/.venv/lib/python3.11/site-packages/gymnasium/envs/registration.py:694: UserWarning: \u001b[33mWARN: Overriding environment myoArmReachFixed-v0 already in registry.\u001b[0m\n",
      "  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n",
      "/home/ubuntu/myochallenge_2025eval/.venv/lib/python3.11/site-packages/gymnasium/envs/registration.py:694: UserWarning: \u001b[33mWARN: Overriding environment myoSarcArmReachFixed-v0 already in registry.\u001b[0m\n",
      "  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n",
      "/home/ubuntu/myochallenge_2025eval/.venv/lib/python3.11/site-packages/gymnasium/envs/registration.py:694: UserWarning: \u001b[33mWARN: Overriding environment myoFatiArmReachFixed-v0 already in registry.\u001b[0m\n",
      "  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n",
      "/home/ubuntu/myochallenge_2025eval/.venv/lib/python3.11/site-packages/gymnasium/envs/registration.py:694: UserWarning: \u001b[33mWARN: Overriding environment myoArmReachRandom-v0 already in registry.\u001b[0m\n",
      "  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n",
      "/home/ubuntu/myochallenge_2025eval/.venv/lib/python3.11/site-packages/gymnasium/envs/registration.py:694: UserWarning: \u001b[33mWARN: Overriding environment myoSarcArmReachRandom-v0 already in registry.\u001b[0m\n",
      "  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n",
      "/home/ubuntu/myochallenge_2025eval/.venv/lib/python3.11/site-packages/gymnasium/envs/registration.py:694: UserWarning: \u001b[33mWARN: Overriding environment myoFatiArmReachRandom-v0 already in registry.\u001b[0m\n",
      "  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyoSuite:> Registering Myo Envs\n",
      "\u001b[36m    MyoSuite: A contact-rich simulation suite for musculoskeletal motor control\n",
      "        Vittorio Caggiano, Huawei Wang, Guillaume Durandau, Massimo Sartori, Vikash Kumar\n",
      "        L4DC-2019 | https://sites.google.com/view/myosuite\n",
      "    \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from hrl.worker_env import TableTennisWorker\n",
    "from config import Config\n",
    "\n",
    "venv = DummyVecEnv([lambda: TableTennisWorker(Config())])\n",
    "obs = venv.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39b2de5d",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "invalid index to scalar variable.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mvenv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvenv\u001b[49m\u001b[43m.\u001b[49m\u001b[43maction_space\u001b[49m\u001b[43m.\u001b[49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/myochallenge_2025eval/.venv/lib/python3.11/site-packages/stable_baselines3/common/vec_env/base_vec_env.py:222\u001b[39m, in \u001b[36mVecEnv.step\u001b[39m\u001b[34m(self, actions)\u001b[39m\n\u001b[32m    215\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    216\u001b[39m \u001b[33;03mStep the environments with the given action\u001b[39;00m\n\u001b[32m    217\u001b[39m \n\u001b[32m    218\u001b[39m \u001b[33;03m:param actions: the action\u001b[39;00m\n\u001b[32m    219\u001b[39m \u001b[33;03m:return: observation, reward, done, information\u001b[39;00m\n\u001b[32m    220\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    221\u001b[39m \u001b[38;5;28mself\u001b[39m.step_async(actions)\n\u001b[32m--> \u001b[39m\u001b[32m222\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/myochallenge_2025eval/.venv/lib/python3.11/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py:59\u001b[39m, in \u001b[36mDummyVecEnv.step_wait\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstep_wait\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> VecEnvStepReturn:\n\u001b[32m     57\u001b[39m     \u001b[38;5;66;03m# Avoid circular imports\u001b[39;00m\n\u001b[32m     58\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m env_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m.num_envs):\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m         obs, \u001b[38;5;28mself\u001b[39m.buf_rews[env_idx], terminated, truncated, \u001b[38;5;28mself\u001b[39m.buf_infos[env_idx] = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43menvs\u001b[49m\u001b[43m[\u001b[49m\u001b[43menv_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[assignment]\u001b[39;49;00m\n\u001b[32m     60\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mactions\u001b[49m\u001b[43m[\u001b[49m\u001b[43menv_idx\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     61\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     62\u001b[39m         \u001b[38;5;66;03m# convert to SB3 VecEnv api\u001b[39;00m\n\u001b[32m     63\u001b[39m         \u001b[38;5;28mself\u001b[39m.buf_dones[env_idx] = terminated \u001b[38;5;129;01mor\u001b[39;00m truncated\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/myochallenge_2025eval/hrl/worker_env.py:93\u001b[39m, in \u001b[36mTableTennisWorker.step\u001b[39m\u001b[34m(self, action)\u001b[39m\n\u001b[32m     92\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action: np.ndarray):\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m     _, base_reward, terminated, truncated, info = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     95\u001b[39m     obs_dict = info[\u001b[33m'\u001b[39m\u001b[33mobs_dict\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     96\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.current_goal \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mWorker goal missing during step()\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/myochallenge_2025eval/custom_env.py:23\u001b[39m, in \u001b[36mCustomEnv.step\u001b[39m\u001b[34m(self, action)\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action: np.ndarray):\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m     obs, reward, terminated, truncated, info = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43menv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m     info = \u001b[38;5;28mdict\u001b[39m(info)\n\u001b[32m     25\u001b[39m     info[\u001b[33m\"\u001b[39m\u001b[33mis_success\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mbool\u001b[39m(info.get(\u001b[33m\"\u001b[39m\u001b[33msolved\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/myochallenge_2025eval/.venv/lib/python3.11/site-packages/gymnasium/wrappers/time_limit.py:57\u001b[39m, in \u001b[36mTimeLimit.step\u001b[39m\u001b[34m(self, action)\u001b[39m\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action):\n\u001b[32m     47\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Steps through the environment and if the number of steps elapsed exceeds ``max_episode_steps`` then truncate.\u001b[39;00m\n\u001b[32m     48\u001b[39m \n\u001b[32m     49\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     55\u001b[39m \n\u001b[32m     56\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m     observation, reward, terminated, truncated, info = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43menv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     58\u001b[39m     \u001b[38;5;28mself\u001b[39m._elapsed_steps += \u001b[32m1\u001b[39m\n\u001b[32m     60\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._elapsed_steps >= \u001b[38;5;28mself\u001b[39m._max_episode_steps:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/myochallenge_2025eval/.venv/lib/python3.11/site-packages/gymnasium/wrappers/order_enforcing.py:56\u001b[39m, in \u001b[36mOrderEnforcing.step\u001b[39m\u001b[34m(self, action)\u001b[39m\n\u001b[32m     54\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._has_reset:\n\u001b[32m     55\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ResetNeeded(\u001b[33m\"\u001b[39m\u001b[33mCannot call env.step() before calling env.reset()\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43menv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/myochallenge_2025eval/.venv/lib/python3.11/site-packages/gymnasium/wrappers/env_checker.py:49\u001b[39m, in \u001b[36mPassiveEnvChecker.step\u001b[39m\u001b[34m(self, action)\u001b[39m\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.checked_step:\n\u001b[32m     48\u001b[39m     \u001b[38;5;28mself\u001b[39m.checked_step = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43menv_step_passive_checker\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.env.step(action)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/myochallenge_2025eval/.venv/lib/python3.11/site-packages/gymnasium/utils/passive_env_checker.py:208\u001b[39m, in \u001b[36menv_step_passive_checker\u001b[39m\u001b[34m(env, action)\u001b[39m\n\u001b[32m    206\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"A passive check for the environment step, investigating the returning data then returning the data unchanged.\"\"\"\u001b[39;00m\n\u001b[32m    207\u001b[39m \u001b[38;5;66;03m# We don't check the action as for some environments then out-of-bounds values can be given\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m208\u001b[39m result = \u001b[43menv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    209\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    210\u001b[39m     result, \u001b[38;5;28mtuple\u001b[39m\n\u001b[32m    211\u001b[39m ), \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExpects step result to be a tuple, actual type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(result)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(result) == \u001b[32m4\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/myochallenge_2025eval/.venv/lib/python3.11/site-packages/myosuite/envs/myo/myochallenge/tabletennis_v0.py:382\u001b[39m, in \u001b[36mTableTennisEnvV0.step\u001b[39m\u001b[34m(self, a, **kwargs)\u001b[39m\n\u001b[32m    379\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.normalize_act:\n\u001b[32m    380\u001b[39m     robotic_act_ind = \u001b[38;5;28mself\u001b[39m.sim.model.actuator_dyntype != mujoco.mjtDyn.mjDYN_MUSCLE\n\u001b[32m    381\u001b[39m     processed_controls[robotic_act_ind] = (np.mean(\u001b[38;5;28mself\u001b[39m.sim.model.actuator_ctrlrange[robotic_act_ind], axis=-\u001b[32m1\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m382\u001b[39m                                            + \u001b[43mprocessed_controls\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrobotic_act_ind\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    383\u001b[39m                                            * (\u001b[38;5;28mself\u001b[39m.sim.model.actuator_ctrlrange[robotic_act_ind, \u001b[32m1\u001b[39m]\n\u001b[32m    384\u001b[39m                                               - \u001b[38;5;28mself\u001b[39m.sim.model.actuator_ctrlrange[robotic_act_ind, \u001b[32m0\u001b[39m]) / \u001b[32m2.0\u001b[39m)\n\u001b[32m    385\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().step(processed_controls, **kwargs)\n",
      "\u001b[31mIndexError\u001b[39m: invalid index to scalar variable."
     ]
    }
   ],
   "source": [
    "venv.step(venv.action_space.sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34f176e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_paddle_normal(sim, paddle_pos, paddle_n, length=0.15):\n",
    "    \"\"\"\n",
    "    Draw a line showing the paddle normal in the viewer.\n",
    "    \"\"\"\n",
    "    start = paddle_pos\n",
    "    end = paddle_pos + length * paddle_n\n",
    "\n",
    "    sim.add_marker(\n",
    "        pos=start,\n",
    "        type=sim.mjtGeom.mjGEOM_ARROW,\n",
    "        size=[length, 0.01, 0.01],\n",
    "        rgba=[1, 0, 0, 1],  # red arrow\n",
    "        mat=None,\n",
    "        label=\"\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfb8df94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from myosuite.utils import gym\n",
    "from utils import quat_to_paddle_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0cf834",
   "metadata": {},
   "outputs": [],
   "source": [
    "from myosuite.utils import gym\n",
    "\n",
    "env = gym.make(\"myoChallengeTableTennisP2-v0\")\n",
    "obs, info = env.reset()\n",
    "\n",
    "for i in range(5):\n",
    "    env.step(env.action_space.sample())\n",
    "\n",
    "    origin = env.sim.data.site_xpos[\n",
    "        env.sim.model.site_name2id(\"paddle_origin\")\n",
    "    ]\n",
    "    tip = env.sim.data.site_xpos[\n",
    "        env.sim.model.site_name2id(\"paddle_normal_tip\")\n",
    "    ]\n",
    "\n",
    "    n = tip - origin\n",
    "    n /= np.linalg.norm(n)\n",
    "    print(f\"[step {i}] site normal:\", n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20164508",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myochallenge_2025eval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
