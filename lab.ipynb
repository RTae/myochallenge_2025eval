{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d64c75f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Make sure this matches your worker observation builder\n",
    "from hrl.worker_env import TableTennisWorker\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from config import Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b6f38bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting relative offsets …\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30000/30000 [05:33<00:00, 90.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Suggested goal bounds ===\n",
      "goal_low  = [2.6226827461719515, 0.09191729348897937, -0.27048435640335083, 2.733618104457855, -0.573699263960123, 0.2]\n",
      "goal_high = [3.141523899316788, 1.236468253314495, -0.15279872941970826, 3.25203111410141, 0.5706091401278972, 0.8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "\n",
    "from config import Config\n",
    "from hrl.worker_env import TableTennisWorker\n",
    "\n",
    "def reset_env(venv):\n",
    "    result = venv.reset()\n",
    "    return result[0] if isinstance(result, tuple) else result\n",
    "\n",
    "def get_base_env(venv):\n",
    "    \"\"\"\n",
    "    Unwrap DummyVecEnv / Monitor / VecNormalize\n",
    "    down to the base gym env that has obs_dict.\n",
    "    \"\"\"\n",
    "    env = venv.envs[0]\n",
    "    while hasattr(env, \"env\"):\n",
    "        env = env.env\n",
    "    return env.unwrapped\n",
    "\n",
    "def collect_relative_offsets(cfg, num_steps=30000):\n",
    "    venv = DummyVecEnv([lambda: TableTennisWorker(cfg)])\n",
    "    base_env = get_base_env(venv)\n",
    "\n",
    "    dxs, dys, dzs = [], [], []\n",
    "    dpxs, dpys = [], []\n",
    "    dts = []\n",
    "\n",
    "    reset_env(venv)\n",
    "    for _ in tqdm(range(num_steps)):\n",
    "        action = [venv.action_space.sample()]\n",
    "        out = venv.step(action)\n",
    "\n",
    "        obs_dict = base_env.obs_dict  # raw MyoSuite obs\n",
    "        ball_pos = np.asarray(obs_dict[\"ball_pos\"], np.float32)\n",
    "        paddle_pos = np.asarray(obs_dict[\"paddle_pos\"], np.float32)\n",
    "        pelvis_xy = np.asarray(obs_dict[\"pelvis_pos\"][:2], np.float32)\n",
    "        t = float(obs_dict[\"time\"])\n",
    "\n",
    "        # Relative differences\n",
    "        dx, dy, dz = paddle_pos - ball_pos\n",
    "        dpx, dpy = pelvis_xy - ball_pos[:2]\n",
    "\n",
    "        dxs.append(dx)\n",
    "        dys.append(dy)\n",
    "        dzs.append(dz)\n",
    "        dpxs.append(dpx)\n",
    "        dpys.append(dpy)\n",
    "        dts.append(t)\n",
    "\n",
    "        done = bool(out[2][0] or out[3][0])\n",
    "        if done:\n",
    "            reset_env(venv)\n",
    "\n",
    "    venv.close()\n",
    "\n",
    "    return {\n",
    "        \"dx\": np.array(dxs),\n",
    "        \"dy\": np.array(dys),\n",
    "        \"dz\": np.array(dzs),\n",
    "        \"dpx\": np.array(dpxs),\n",
    "        \"dpy\": np.array(dpys),\n",
    "        \"dt\": np.array(dts),\n",
    "    }\n",
    "\n",
    "def suggest_goal_bounds(data, pct_min=1, pct_max=99, slack=1.2):\n",
    "    low, high = {}, {}\n",
    "    for key, values in data.items():\n",
    "        lo = np.percentile(values, pct_min)\n",
    "        hi = np.percentile(values, pct_max)\n",
    "        center = 0.5 * (lo + hi)\n",
    "        width = (hi - lo) * slack\n",
    "        low[key]  = center - 0.5 * width\n",
    "        high[key] = center + 0.5 * width\n",
    "    return low, high\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    cfg = Config()\n",
    "    print(\"Collecting relative offsets …\")\n",
    "    data = collect_relative_offsets(cfg, num_steps=30000)\n",
    "\n",
    "    low, high = suggest_goal_bounds(data, pct_min=1, pct_max=99, slack=1.2)\n",
    "    print(\"=== Suggested goal bounds ===\")\n",
    "    print(\"goal_low  =\", [\n",
    "        low[\"dx\"], low[\"dy\"], low[\"dz\"],\n",
    "        low[\"dpx\"], low[\"dpy\"], 0.2\n",
    "    ])\n",
    "    print(\"goal_high =\", [\n",
    "        high[\"dx\"], high[\"dy\"], high[\"dz\"],\n",
    "        high[\"dpx\"], high[\"dpy\"], 0.8\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b168eb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from hrl.worker_env import TableTennisWorker\n",
    "from config import Config\n",
    "\n",
    "venv = DummyVecEnv([lambda: TableTennisWorker(Config())])\n",
    "obs = venv.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b2de5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/myochallenge_2025eval/.venv/lib/python3.11/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.obs_dict to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.obs_dict` for environment variables or `env.get_wrapper_attr('obs_dict')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'time': array([0.]),\n",
       " 'pelvis_pos': array([ 2.0205e+00, -6.6971e-04,  9.5000e-01]),\n",
       " 'body_qpos': array([-0.4205,  0.    ,  0.    ,  0.    ,  0.    ,  0.    ,  0.    ,\n",
       "         0.    ,  0.    ,  0.    ,  0.    , -0.0972,  0.    ,  0.    ,\n",
       "         0.    ,  0.    ,  0.    ,  0.    ,  0.    ,  0.    ,  0.    ,\n",
       "         0.    ,  0.    ,  0.    ,  0.    ,  0.    ,  0.    ,  0.    ,\n",
       "         0.    ,  0.1368,  0.1484,  0.7069, -0.7405, -0.3432,  0.8055,\n",
       "        -0.1028, -0.0829, -0.7304,  0.0632,  0.7   ,  0.075 , -0.2967,\n",
       "         0.7227, -0.1361,  0.2671,  0.3535,  0.6598, -0.1518,  0.4242,\n",
       "         0.5184,  0.919 , -0.2094,  0.2592,  0.5106,  0.7934, -0.2042,\n",
       "         0.2278,  0.    ]),\n",
       " 'body_qvel': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'ball_pos': array([-0.9342,  0.1557,  1.4482]),\n",
       " 'ball_vel': array([ 5.6716, -0.8552, -0.0892]),\n",
       " 'paddle_pos': array([1.91  , 0.6677, 1.2373]),\n",
       " 'paddle_vel': array([0., 0., 0.]),\n",
       " 'paddle_ori': array([ 0.6994, -0.1057,  0.6989, -0.1056]),\n",
       " 'padde_ori_err': array([ 7.0345e-08, -2.3804e-07, -1.6457e-07, -2.1125e-01]),\n",
       " 'reach_err': array([ 2.8441,  0.512 , -0.2109]),\n",
       " 'palm_pos': array([1.9022, 0.6528, 1.1417]),\n",
       " 'palm_err': array([-0.0077, -0.0149, -0.0957]),\n",
       " 'touching_info': array([0, 0, 0, 0, 0, 0]),\n",
       " 'act': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0.])}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cfb8df94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from myosuite.utils import gym\n",
    "\n",
    "\n",
    "env = gym.make(\"myoChallengeTableTennisP2-v0\", max_episode_steps=1000)\n",
    "obs = env.reset()\n",
    "obs, reward, terminated, truncated, info = env.step(env.action_space.sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "121d2cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time                 shape=()\n",
      "pelvis_pos           shape=(3,)\n",
      "body_qpos            shape=(58,)\n",
      "body_qvel            shape=(58,)\n",
      "ball_pos             shape=(3,)\n",
      "ball_vel             shape=(3,)\n",
      "paddle_pos           shape=(3,)\n",
      "paddle_vel           shape=(3,)\n",
      "paddle_ori           shape=(4,)\n",
      "padde_ori_err        shape=(4,)\n",
      "reach_err            shape=(3,)\n",
      "palm_pos             shape=(3,)\n",
      "palm_err             shape=(3,)\n",
      "touching_info        shape=(6,)\n",
      "act                  shape=(273,)\n"
     ]
    }
   ],
   "source": [
    "for k, v in info['obs_dict'].items():\n",
    "    try:\n",
    "        print(f\"{k:20s} shape={np.asarray(v).shape}\")\n",
    "    except Exception as e:\n",
    "        print(f\"{k:20s} ERROR {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f879cf1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0.01)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info['obs_dict']['time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd67ea6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myochallenge_2025eval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
