{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d64c75f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n",
      "Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n",
      "Users of this version of Gym should be able to simply replace 'import gym' with 'import gymnasium as gym' in the vast majority of cases.\n",
      "See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n",
      "/home/ubuntu/myochallenge_2025eval/.venv/lib/python3.11/site-packages/gymnasium/envs/registration.py:694: UserWarning: \u001b[33mWARN: Overriding environment myoArmReachFixed-v0 already in registry.\u001b[0m\n",
      "  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n",
      "/home/ubuntu/myochallenge_2025eval/.venv/lib/python3.11/site-packages/gymnasium/envs/registration.py:694: UserWarning: \u001b[33mWARN: Overriding environment myoSarcArmReachFixed-v0 already in registry.\u001b[0m\n",
      "  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n",
      "/home/ubuntu/myochallenge_2025eval/.venv/lib/python3.11/site-packages/gymnasium/envs/registration.py:694: UserWarning: \u001b[33mWARN: Overriding environment myoFatiArmReachFixed-v0 already in registry.\u001b[0m\n",
      "  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n",
      "/home/ubuntu/myochallenge_2025eval/.venv/lib/python3.11/site-packages/gymnasium/envs/registration.py:694: UserWarning: \u001b[33mWARN: Overriding environment myoArmReachRandom-v0 already in registry.\u001b[0m\n",
      "  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n",
      "/home/ubuntu/myochallenge_2025eval/.venv/lib/python3.11/site-packages/gymnasium/envs/registration.py:694: UserWarning: \u001b[33mWARN: Overriding environment myoSarcArmReachRandom-v0 already in registry.\u001b[0m\n",
      "  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n",
      "/home/ubuntu/myochallenge_2025eval/.venv/lib/python3.11/site-packages/gymnasium/envs/registration.py:694: UserWarning: \u001b[33mWARN: Overriding environment myoFatiArmReachRandom-v0 already in registry.\u001b[0m\n",
      "  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyoSuite:> Registering Myo Envs\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Make sure this matches your worker observation builder\n",
    "from hrl.worker_env import TableTennisWorker\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from config import Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b6f38bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting relative offsets …\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30000/30000 [05:33<00:00, 90.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Suggested goal bounds ===\n",
      "goal_low  = [2.6226827461719515, 0.09191729348897937, -0.27048435640335083, 2.733618104457855, -0.573699263960123, 0.2]\n",
      "goal_high = [3.141523899316788, 1.236468253314495, -0.15279872941970826, 3.25203111410141, 0.5706091401278972, 0.8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "\n",
    "from config import Config\n",
    "from hrl.worker_env import TableTennisWorker\n",
    "\n",
    "def reset_env(venv):\n",
    "    result = venv.reset()\n",
    "    return result[0] if isinstance(result, tuple) else result\n",
    "\n",
    "def get_base_env(venv):\n",
    "    \"\"\"\n",
    "    Unwrap DummyVecEnv / Monitor / VecNormalize\n",
    "    down to the base gym env that has obs_dict.\n",
    "    \"\"\"\n",
    "    env = venv.envs[0]\n",
    "    while hasattr(env, \"env\"):\n",
    "        env = env.env\n",
    "    return env.unwrapped\n",
    "\n",
    "def collect_relative_offsets(cfg, num_steps=30000):\n",
    "    venv = DummyVecEnv([lambda: TableTennisWorker(cfg)])\n",
    "    base_env = get_base_env(venv)\n",
    "\n",
    "    dxs, dys, dzs = [], [], []\n",
    "    dpxs, dpys = [], []\n",
    "    dts = []\n",
    "\n",
    "    reset_env(venv)\n",
    "    for _ in tqdm(range(num_steps)):\n",
    "        action = [venv.action_space.sample()]\n",
    "        out = venv.step(action)\n",
    "\n",
    "        obs_dict = base_env.obs_dict  # raw MyoSuite obs\n",
    "        ball_pos = np.asarray(obs_dict[\"ball_pos\"], np.float32)\n",
    "        paddle_pos = np.asarray(obs_dict[\"paddle_pos\"], np.float32)\n",
    "        pelvis_xy = np.asarray(obs_dict[\"pelvis_pos\"][:2], np.float32)\n",
    "        t = float(obs_dict[\"time\"])\n",
    "\n",
    "        # Relative differences\n",
    "        dx, dy, dz = paddle_pos - ball_pos\n",
    "        dpx, dpy = pelvis_xy - ball_pos[:2]\n",
    "\n",
    "        dxs.append(dx)\n",
    "        dys.append(dy)\n",
    "        dzs.append(dz)\n",
    "        dpxs.append(dpx)\n",
    "        dpys.append(dpy)\n",
    "        dts.append(t)\n",
    "\n",
    "        done = bool(out[2][0] or out[3][0])\n",
    "        if done:\n",
    "            reset_env(venv)\n",
    "\n",
    "    venv.close()\n",
    "\n",
    "    return {\n",
    "        \"dx\": np.array(dxs),\n",
    "        \"dy\": np.array(dys),\n",
    "        \"dz\": np.array(dzs),\n",
    "        \"dpx\": np.array(dpxs),\n",
    "        \"dpy\": np.array(dpys),\n",
    "        \"dt\": np.array(dts),\n",
    "    }\n",
    "\n",
    "def suggest_goal_bounds(data, pct_min=1, pct_max=99, slack=1.2):\n",
    "    low, high = {}, {}\n",
    "    for key, values in data.items():\n",
    "        lo = np.percentile(values, pct_min)\n",
    "        hi = np.percentile(values, pct_max)\n",
    "        center = 0.5 * (lo + hi)\n",
    "        width = (hi - lo) * slack\n",
    "        low[key]  = center - 0.5 * width\n",
    "        high[key] = center + 0.5 * width\n",
    "    return low, high\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    cfg = Config()\n",
    "    print(\"Collecting relative offsets …\")\n",
    "    data = collect_relative_offsets(cfg, num_steps=30000)\n",
    "\n",
    "    low, high = suggest_goal_bounds(data, pct_min=1, pct_max=99, slack=1.2)\n",
    "    print(\"=== Suggested goal bounds ===\")\n",
    "    print(\"goal_low  =\", [\n",
    "        low[\"dx\"], low[\"dy\"], low[\"dz\"],\n",
    "        low[\"dpx\"], low[\"dpy\"], 0.2\n",
    "    ])\n",
    "    print(\"goal_high =\", [\n",
    "        high[\"dx\"], high[\"dy\"], high[\"dz\"],\n",
    "        high[\"dpx\"], high[\"dpy\"], 0.8\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b168eb02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "worker obs shape: (21,)\n",
      "worker obs first 20 values: [ 2.7610e+00  3.8830e-01 -1.8496e-01  0.0000e+00  0.0000e+00  0.0000e+00\n",
      "  5.6894e+00 -1.2955e+00  2.0753e-02  1.0000e+00  2.5332e-07 -7.9679e-04\n",
      "  2.8715e+00 -2.8010e-01  0.0000e+00 -8.3748e-01 -2.4921e-01 -2.8526e-01\n",
      " -3.2527e-01 -4.3313e-01]\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from hrl.worker_env import TableTennisWorker\n",
    "from config import Config\n",
    "\n",
    "venv = DummyVecEnv([lambda: TableTennisWorker(Config())])\n",
    "obs = venv.reset()\n",
    "w = obs[0]\n",
    "\n",
    "print(\"worker obs shape:\", w.shape)\n",
    "print(\"worker obs first 20 values:\", w[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cfb8df94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from myosuite.utils import gym\n",
    "\n",
    "\n",
    "env = gym.make(\"myoChallengeTableTennisP2-v0\", max_episode_steps=1000)\n",
    "obs = env.reset()\n",
    "obs, reward, terminated, truncated, info = env.step(env.action_space.sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "121d2cee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['time', 'pelvis_pos', 'body_qpos', 'body_qvel', 'ball_pos', 'ball_vel', 'paddle_pos', 'paddle_vel', 'paddle_ori', 'padde_ori_err', 'reach_err', 'palm_pos', 'palm_err', 'touching_info', 'act'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info['obs_dict'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f879cf1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myochallenge_2025eval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
